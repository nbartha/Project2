# AER850 PROJECT 2 - DCNN MODEL IMPLEMENTATION

# Step 2.0 - importing the libraries

import os
import zipfile
import numpy as np
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers, models
from tensorflow.keras.layers import LeakyReLU
from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array
import matplotlib.pyplot as plt

# Check TensorFlow and Keras versions
print(f"\nTensorFlow Version: {tf.__version__}")
print(f"Keras Version: {keras.__version__}\n")

# Sstep 2.1 - DATA EXTRACTION AND PROCESSING

# Define file paths
zip_path = "DataSet.zip"
extract_dir = "Data" # Corrected directory name

# Automatically extract ZIP file if not already extracted
if not os.path.exists(extract_dir):
    with zipfile.ZipFile(zip_path, 'r') as zip_ref:
        zip_ref.extractall("Data") # Extract to 'Data' directory
    print(f" Dataset extracted successfully to: {extract_dir}")
else:
    print(f" Dataset already exists at: {extract_dir}")

# Confirm folder structure
for root, dirs, files in os.walk(extract_dir):
    print(root, "->", len(files), "files")

# Define image parameters
img_height, img_width = 500, 500
img_channel = 3
batch_size = 32
img_shape = (img_width, img_height, img_channel)

# Define directory paths
train_directory = os.path.join(extract_dir, "Data", "train")
valid_directory = os.path.join(extract_dir, "Data", "valid")

# Data augmentation for training
train_datagen = ImageDataGenerator(
    rescale=1./255,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True
)

# Only rescaling for validation
valid_datagen = ImageDataGenerator(rescale=1./255)

# Create data generators
train_generator = train_datagen.flow_from_directory(
    train_directory,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical'
)

validation_generator = valid_datagen.flow_from_directory(
    valid_directory,
    target_size=(img_height, img_width),
    batch_size=batch_size,
    class_mode='categorical'
)

print("\nTrain Samples:", train_generator.samples)
print("Validation Samples:", validation_generator.samples)
print("Class Indices:", train_generator.class_indices)


# step 2.1b - VISUALIZE SAMPLE IMAGES


images, labels = next(train_generator)
class_names = list(train_generator.class_indices.keys())

plt.figure(figsize=(10, 10))
for i in range(9):
    plt.subplot(3, 3, i + 1)
    plt.imshow(images[i])
    plt.title(class_names[np.argmax(labels[i])])
    plt.axis("off")
plt.suptitle("Sample Training Images")
plt.show()


# step 2.2 - NEURAL NETWORK ARCHITECTURE DESIGN


dcnn_model = models.Sequential([
    layers.Input(shape=img_shape),

    # Convolution Block 1
    layers.Conv2D(32, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),

    # Convolution Block 2
    layers.Conv2D(64, (3, 3)),
    LeakyReLU(negative_slope=0.01),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.25),

    # Convolution Block 3
    layers.Conv2D(128, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.3),

    # Convolution Block 4
    layers.Conv2D(256, (3, 3), activation='relu'),
    layers.MaxPooling2D((2, 2)),
    layers.Dropout(0.4),

    # Flatten + Fully Connected Layers
    layers.Flatten(),
    layers.Dense(64, activation='relu'),
    layers.Dropout(0.5),

    # Output Layer (3 classes)
    layers.Dense(3, activation='softmax')
])

dcnn_model.compile(optimizer='adam',
                   loss='categorical_crossentropy',
                   metrics=['accuracy'])

dcnn_model.summary()

# step 2.4 - MODEL TRAINING

training_history = dcnn_model.fit(
    train_generator,
    epochs=30,
    validation_data=validation_generator
)


